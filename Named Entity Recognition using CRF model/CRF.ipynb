{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition using CRF model\n",
    "In Natural Language Processing (NLP) an Entity Recognition is one of the common problem. The entity is referred to as the part of the text that is interested in. In NLP, NER is a method of extracting the relevant information from a large corpus and classifying those entities into predefined categories such as location, organization, name and so on. \n",
    "Information about lables: \n",
    "* geo = Geographical Entity\n",
    "* org = Organization\n",
    "* per = Person\n",
    "* gpe = Geopolitical Entity\n",
    "* tim = Time indicator\n",
    "* art = Artifact\n",
    "* eve = Event\n",
    "* nat = Natural Phenomenon\n",
    "\n",
    "        1. Total Words Count = 1354149 \n",
    "        2. Target Data Column: Tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_f1_score\n",
    "from sklearn_crfsuite.metrics import flat_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the csv file\n",
    "df = pd.read_csv(\"Annotated/GMB_dataset.txt\", sep=\"\\t\", encoding=\"latin1\")\n",
    "del df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence #           Word  POS    Tag\n",
       "0         1.0      Thousands  NNS      O\n",
       "1         1.0             of   IN      O\n",
       "2         1.0  demonstrators  NNS      O\n",
       "3         1.0           have  VBP      O\n",
       "4         1.0        marched  VBN      O\n",
       "5         1.0        through   IN      O\n",
       "6         1.0         London  NNP  B-geo\n",
       "7         1.0             to   TO      O\n",
       "8         1.0        protest   VB      O\n",
       "9         1.0            the   DT      O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display first 10 rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>15.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66071</th>\n",
       "      <td>2996.0</td>\n",
       "      <td>13</td>\n",
       "      <td>CD</td>\n",
       "      <td>I-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66072</th>\n",
       "      <td>2996.0</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>I-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66073</th>\n",
       "      <td>2996.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>CD</td>\n",
       "      <td>I-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66124</th>\n",
       "      <td>2997.0</td>\n",
       "      <td>1982</td>\n",
       "      <td>CD</td>\n",
       "      <td>B-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66158</th>\n",
       "      <td>2999.0</td>\n",
       "      <td>within</td>\n",
       "      <td>IN</td>\n",
       "      <td>B-tim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence #       Word  POS    Tag\n",
       "167           8.0  Wednesday  NNP  B-tim\n",
       "211          10.0  Wednesday  NNP  B-tim\n",
       "274          13.0    Tuesday  NNP  B-tim\n",
       "341          15.0  Wednesday  NNP  B-tim\n",
       "493          21.0  Wednesday  NNP  B-tim\n",
       "...           ...        ...  ...    ...\n",
       "66071      2996.0         13   CD  I-tim\n",
       "66072      2996.0          ,    ,  I-tim\n",
       "66073      2996.0       2005   CD  I-tim\n",
       "66124      2997.0       1982   CD  B-tim\n",
       "66158      2999.0     within   IN  B-tim\n",
       "\n",
       "[1494 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Tag == 'B-tim') | (df.Tag == 'I-tim')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>66161.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1494.085594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>864.286211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>746.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1484.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2255.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentence #\n",
       "count  66161.000000\n",
       "mean    1494.085594\n",
       "std      864.286211\n",
       "min        1.000000\n",
       "25%      746.000000\n",
       "50%     1484.000000\n",
       "75%     2255.000000\n",
       "max     2999.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations : \n",
    "* There are total 47959 sentences in the dataset.\n",
    "* Number unique words in the dataset are 35178.\n",
    "* Total 17 lables (Tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
       "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
       "       'I-eve', 'I-nat'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the unique Tags\n",
    "df['Tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #    0\n",
       "Word          0\n",
       "POS           0\n",
       "Tag           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking null values, if any.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of missing values in 'Sentence #' attribute. So we will use pandas fillna technique and use 'ffill' method which propagates last valid observation forward to next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a class te get sentence. The each sentence will be list of tuples with its tag and pos.\n",
    "class sentence(object):\n",
    "    def __init__(self, df):\n",
    "        self.n_sent = 1\n",
    "        self.df = df\n",
    "        self.empty = False\n",
    "        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
    "                                                       s['POS'].values.tolist(),\n",
    "                                                       s['Tag'].values.tolist())]\n",
    "        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_text(self):\n",
    "        try:\n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent +=1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying one full sentence\n",
    "getter = sentence(df)\n",
    "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Families of soldiers killed in the conflict joined the protesters who carried banners with such slogans as \" Bush Number One Terrorist \" and \" Stop the Bombings . \"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#sentence with its pos and tag.\n",
    "sent = getter.get_text()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting all the sentences in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Preparation\n",
    "These are the default features used by the NER in nltk. We can also modify it for our customization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in all_sentences]\n",
    "y = [sent2labels(s) for s in all_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(algorithm = 'lbfgs',\n",
    "         c1 = 0.1,\n",
    "         c2 = 0.1,\n",
    "         max_iterations = 100,\n",
    "         all_possible_transitions = True,\n",
    "         keep_tempfiles=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tags = crf.predict(X_test)\n",
    "\n",
    "# Get marginal probabilities\n",
    "marginals = crf.predict_marginals(X_test)\n",
    "\n",
    "for i, seq in enumerate(X_test):\n",
    "    for j, token in enumerate(seq):\n",
    "        word = token['word.lower()']\n",
    "        tag = predicted_tags[i][j]\n",
    "        confidence = marginals[i][j][tag]\n",
    "        print(f\"{word}, {tag}, {confidence:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Predicting on the test set.\n",
    "# y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model performance.\n",
    "We will use precision, recall and f1-score metrics to evaluate the performance of the model since the accuracy is not a good metric for this dataset because we have an unequal number of data points in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-org',\n",
       " 'I-org',\n",
       " 'B-gpe',\n",
       " 'I-gpe',\n",
       " 'B-tim',\n",
       " 'B-geo',\n",
       " 'I-geo',\n",
       " 'B-per',\n",
       " 'I-per',\n",
       " 'I-tim',\n",
       " 'B-nat',\n",
       " 'I-nat',\n",
       " 'B-eve',\n",
       " 'I-eve',\n",
       " 'B-art',\n",
       " 'I-art']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9568286221325394\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division\n",
    "from functools import wraps\n",
    "\n",
    "from sklearn_crfsuite.utils import flatten\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "f1_score = flat_f1_score(y_test, y_pred, average='weighted')\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-art',\n",
       " 'I-art',\n",
       " 'B-eve',\n",
       " 'I-eve',\n",
       " 'B-geo',\n",
       " 'I-geo',\n",
       " 'B-gpe',\n",
       " 'I-gpe',\n",
       " 'B-nat',\n",
       " 'I-nat',\n",
       " 'B-org',\n",
       " 'I-org',\n",
       " 'B-per',\n",
       " 'I-per',\n",
       " 'B-tim',\n",
       " 'I-tim']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "sorted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00        15\n",
      "       B-eve       0.80      0.67      0.73         6\n",
      "       B-geo       0.75      0.87      0.81       398\n",
      "       B-gpe       0.90      0.78      0.84       257\n",
      "       B-nat       1.00      0.20      0.33         5\n",
      "       B-org       0.71      0.65      0.68       244\n",
      "       B-per       0.81      0.80      0.80       226\n",
      "       B-tim       0.90      0.82      0.86       248\n",
      "       I-art       0.00      0.00      0.00        12\n",
      "       I-eve       0.75      0.75      0.75         4\n",
      "       I-geo       0.74      0.70      0.72        81\n",
      "       I-gpe       0.00      0.00      0.00         9\n",
      "       I-nat       1.00      0.25      0.40         4\n",
      "       I-org       0.67      0.71      0.69       176\n",
      "       I-per       0.81      0.90      0.85       256\n",
      "       I-tim       0.79      0.40      0.54        84\n",
      "           O       0.99      0.99      0.99     11409\n",
      "\n",
      "    accuracy                           0.96     13434\n",
      "   macro avg       0.68      0.56      0.59     13434\n",
      "weighted avg       0.96      0.96      0.96     13434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_test_flat = [tag for seq in y_test for tag in seq]\n",
    "y_pred_flat = [tag for seq in y_pred for tag in seq]\n",
    "\n",
    "print(classification_report(y_test_flat, y_pred_flat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7811348563006633\n",
      "Recall: 0.7576840600428878\n",
      "F1-Score: 0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# import random\n",
    "# import matplotlib\n",
    "# fig, ax = plt.subplots(figsize=(30,10))\n",
    "# font = {'family' : 'normal',\n",
    "#         'size'   : 16}\n",
    "# matplotlib.rc('font', **font)\n",
    "# final_text = []\n",
    "# color = []\n",
    "# samples = 10\n",
    "# integer = random.randint(0,500)\n",
    "# prediction = crf.predict(X_test[integer:integer+samples])\n",
    "# for x,y in zip(sentences[integer:integer+samples], prediction):\n",
    "#     for x1,y1, in zip(x,y):\n",
    "#         if y1!='O':\n",
    "#             final_text.append('<{}>'.format(x1[0]))\n",
    "#             if y1[0]=='I':\n",
    "#                 color.append(color[-1])\n",
    "#             else:\n",
    "#                   color.append ({'color':random.choice(['blue','green','red','magenta'])})\n",
    "#         else:\n",
    "#             final_text.append(x1[0])\n",
    "#     final_text.append('\\n')\n",
    "# # You can either create a HighlightText object\n",
    "# HighlightText(x=0, y=0.75,\n",
    "#               s=' '.join(final_text),\n",
    "#               highlight_textprops=color,\n",
    "#               ax=ax)\n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks quite nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
